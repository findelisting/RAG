{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16d4e249",
   "metadata": {},
   "source": [
    "notion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663ed6fc",
   "metadata": {},
   "source": [
    "For notion to wokr you have to creation a notion api integration code: https://www.notion.so/profile/integrations\n",
    "\n",
    "And then give access to all the pages that you want to access this integrations and then copy the page id which are the last alphanumeric code without any dashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7179fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.notion import NotionPageReader\n",
    "\n",
    "# Initialize NotionPageReader\n",
    "reader = NotionPageReader(integration_token=\"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\")\n",
    "\n",
    "# Load data from Notion\n",
    "documents = reader.load_data(\n",
    "    page_ids=[\"285aa20e4f15801fa57fc011ad93dacf\", \"286aa20e4f15801a9ae2c8c159429b5f\", ],  # List of page IDs to load\n",
    "    #database_ids=\"XXX\",  # Database ID from which to load page IDs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbca790",
   "metadata": {},
   "source": [
    "IF the page has a lot of pages etc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "674b33cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from llama_index.readers.notion import NotionPageReader\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "reader = NotionPageReader(integration_token=\"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\")\n",
    "\n",
    "page_ids = [\"285aa20e4f15801fa57fc011ad93dacf\", \"48b8201c83484e5cb9ea63d8d50801f2\"]\n",
    "max_attempts = 5\n",
    "\n",
    "for attempt in range(max_attempts):\n",
    "    try:\n",
    "        documents = reader.load_data(page_ids=page_ids)\n",
    "        print(\"Loaded successfully!\")\n",
    "        break\n",
    "    except RequestException as e:\n",
    "        print(f\"Attempt {attempt+1} failed: {e}\")\n",
    "        time.sleep(5)  # wait 5 seconds before retry\n",
    "else:\n",
    "    print(\"Failed after several attempts. Consider splitting large pages.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa51c5c",
   "metadata": {},
   "source": [
    "**google drive**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393e41a7",
   "metadata": {},
   "source": [
    "You have to first pip install below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e5bbeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama_index.readers.google\n",
      "  Downloading llama_index_readers_google-0.7.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting gkeepapi<0.16,>=0.15.1 (from llama_index.readers.google)\n",
      "  Downloading gkeepapi-0.15.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting google-api-python-client<3,>=2.115.0 (from llama_index.readers.google)\n",
      "  Downloading google_api_python_client-2.184.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting google-auth-httplib2<0.3,>=0.2.0 (from llama_index.readers.google)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-oauthlib<2,>=1.2.0 (from llama_index.readers.google)\n",
      "  Downloading google_auth_oauthlib-1.2.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: llama-index-core<0.15,>=0.13.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama_index.readers.google) (0.14.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama_index.readers.google) (2.2.3)\n",
      "Collecting pydrive<2,>=1.3.1 (from llama_index.readers.google)\n",
      "  Downloading PyDrive-1.3.1.tar.gz (987 kB)\n",
      "     ---------------------------------------- 0.0/987.4 kB ? eta -:--:--\n",
      "     ---------- ----------------------------- 262.1/987.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 987.4/987.4 kB 3.2 MB/s  0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting gpsoauth>=1.0.3 (from gkeepapi<0.16,>=0.15.1->llama_index.readers.google)\n",
      "  Downloading gpsoauth-2.0.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting future>=0.16.0 (from gkeepapi<0.16,>=0.15.1->llama_index.readers.google)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client<3,>=2.115.0->llama_index.readers.google)\n",
      "  Downloading httplib2-0.31.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client<3,>=2.115.0->llama_index.readers.google) (2.40.3)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 (from google-api-python-client<3,>=2.115.0->llama_index.readers.google)\n",
      "  Downloading google_api_core-2.25.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client<3,>=2.115.0->llama_index.readers.google)\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client<3,>=2.115.0->llama_index.readers.google) (1.70.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client<3,>=2.115.0->llama_index.readers.google) (5.29.5)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client<3,>=2.115.0->llama_index.readers.google)\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client<3,>=2.115.0->llama_index.readers.google) (2.32.5)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3,>=2.115.0->llama_index.readers.google) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3,>=2.115.0->llama_index.readers.google) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3,>=2.115.0->llama_index.readers.google) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth-oauthlib<2,>=1.2.0->llama_index.readers.google) (2.0.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client<3,>=2.115.0->llama_index.readers.google) (3.2.3)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (3.12.13)\n",
      "Requirement already satisfied: aiosqlite in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (2025.3.2)\n",
      "Requirement already satisfied: httpx in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<3,>=2 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (2.6.0)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\users\\redi user\\appdata\\roaming\\python\\python313\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (2.2.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (11.2.1)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (4.4.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (2.11.9)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (6.0.2)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (2.0.41)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (4.13.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (6.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (1.20.1)\n",
      "Requirement already satisfied: griffe in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (1.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (3.1.6)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from llama-index-workflows<3,>=2->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (0.3.0)\n",
      "Collecting oauth2client>=4.0.0 (from pydrive<2,>=1.3.1->llama_index.readers.google)\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client<3,>=2.115.0->llama_index.readers.google) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client<3,>=2.115.0->llama_index.readers.google) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client<3,>=2.115.0->llama_index.readers.google) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client<3,>=2.115.0->llama_index.readers.google) (2025.10.5)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3,>=2.115.0->llama_index.readers.google) (0.6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\redi user\\appdata\\roaming\\python\\python313\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (0.4.6)\n",
      "Collecting pycryptodomex>=3.0 (from gpsoauth>=1.0.3->gkeepapi<0.16,>=0.15.1->llama_index.readers.google)\n",
      "  Downloading pycryptodomex-3.23.0-cp37-abi3-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: click in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (2024.11.6)\n",
      "Requirement already satisfied: six>=1.6.1 in c:\\users\\redi user\\appdata\\roaming\\python\\python313\\site-packages (from oauth2client>=4.0.0->pydrive<2,>=1.3.1->llama_index.readers.google) (1.17.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (0.4.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=1.2.0->llama_index.readers.google) (3.3.1)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama_index.readers.google) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\redi user\\appdata\\roaming\\python\\python313\\site-packages (from pandas->llama_index.readers.google) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->llama_index.readers.google) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\redi user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->llama_index.readers.google) (2025.2)\n",
      "Downloading llama_index_readers_google-0.7.2-py3-none-any.whl (34 kB)\n",
      "Downloading gkeepapi-0.15.1-py3-none-any.whl (22 kB)\n",
      "Downloading google_api_python_client-2.184.0-py3-none-any.whl (14.3 MB)\n",
      "   ---------------------------------------- 0.0/14.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/14.3 MB 5.0 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.1/14.3 MB 5.4 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 3.4/14.3 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.5/14.3 MB 5.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.3/14.3 MB 6.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 7.3/14.3 MB 6.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.4/14.3 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.2/14.3 MB 5.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 9.7/14.3 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 10.7/14.3 MB 5.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.8/14.3 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.3/14.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.1/14.3 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.6/14.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.2/14.3 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.3/14.3 MB 4.5 MB/s  0:00:03\n",
      "Downloading google_api_core-2.25.2-py3-none-any.whl (162 kB)\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading google_auth_oauthlib-1.2.2-py3-none-any.whl (19 kB)\n",
      "Downloading httplib2-0.31.0-py3-none-any.whl (91 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Downloading gpsoauth-2.0.0-py3-none-any.whl (7.4 kB)\n",
      "Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "Downloading pycryptodomex-3.23.0-cp37-abi3-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 2.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 1.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.6/1.8 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 1.4 MB/s  0:00:01\n",
      "Building wheels for collected packages: pydrive\n",
      "  Building wheel for pydrive (pyproject.toml): started\n",
      "  Building wheel for pydrive (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pydrive: filename=pydrive-1.3.1-py3-none-any.whl size=27565 sha256=4fd20f25284043b7df96d1ef48bee88ed39a6bdb8765417b8523c5904824a2dc\n",
      "  Stored in directory: c:\\users\\redi user\\appdata\\local\\pip\\cache\\wheels\\48\\43\\57\\916331748bfed9cb688b4bab0121ca70f2c60b1a181c9273cf\n",
      "Successfully built pydrive\n",
      "Installing collected packages: uritemplate, pycryptodomex, proto-plus, httplib2, future, oauth2client, gpsoauth, google-auth-oauthlib, google-auth-httplib2, google-api-core, gkeepapi, google-api-python-client, pydrive, llama_index.readers.google\n",
      "\n",
      "   ----------------------------------------  0/14 [uritemplate]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   -- -------------------------------------  1/14 [pycryptodomex]\n",
      "   ----- ----------------------------------  2/14 [proto-plus]\n",
      "   ----- ----------------------------------  2/14 [proto-plus]\n",
      "   ----- ----------------------------------  2/14 [proto-plus]\n",
      "   ----- ----------------------------------  2/14 [proto-plus]\n",
      "   ----- ----------------------------------  2/14 [proto-plus]\n",
      "   -------- -------------------------------  3/14 [httplib2]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   ----------- ----------------------------  4/14 [future]\n",
      "   -------------- -------------------------  5/14 [oauth2client]\n",
      "   -------------- -------------------------  5/14 [oauth2client]\n",
      "   -------------- -------------------------  5/14 [oauth2client]\n",
      "   -------------- -------------------------  5/14 [oauth2client]\n",
      "   -------------- -------------------------  5/14 [oauth2client]\n",
      "   -------------- -------------------------  5/14 [oauth2client]\n",
      "   -------------- -------------------------  5/14 [oauth2client]\n",
      "   -------------- -------------------------  5/14 [oauth2client]\n",
      "   -------------- -------------------------  5/14 [oauth2client]\n",
      "   ----------------- ----------------------  6/14 [gpsoauth]\n",
      "   -------------------- -------------------  7/14 [google-auth-oauthlib]\n",
      "   -------------------- -------------------  7/14 [google-auth-oauthlib]\n",
      "   -------------------- -------------------  7/14 [google-auth-oauthlib]\n",
      "   -------------------- -------------------  7/14 [google-auth-oauthlib]\n",
      "   ------------------------- --------------  9/14 [google-api-core]\n",
      "   ------------------------- --------------  9/14 [google-api-core]\n",
      "   ------------------------- --------------  9/14 [google-api-core]\n",
      "   ------------------------- --------------  9/14 [google-api-core]\n",
      "   ------------------------- --------------  9/14 [google-api-core]\n",
      "   ------------------------- --------------  9/14 [google-api-core]\n",
      "   ------------------------- --------------  9/14 [google-api-core]\n",
      "   ------------------------- --------------  9/14 [google-api-core]\n",
      "   ------------------------- --------------  9/14 [google-api-core]\n",
      "   ------------------------- --------------  9/14 [google-api-core]\n",
      "   ------------------------- --------------  9/14 [google-api-core]\n",
      "   ------------------------- --------------  9/14 [google-api-core]\n",
      "   ------------------------- --------------  9/14 [google-api-core]\n",
      "   ------------------------- --------------  9/14 [google-api-core]\n",
      "   ------------------------- --------------  9/14 [google-api-core]\n",
      "   ---------------------------- ----------- 10/14 [gkeepapi]\n",
      "   ---------------------------- ----------- 10/14 [gkeepapi]\n",
      "   ------------------------------- -------- 11/14 [google-api-python-client]\n",
      "   ------------------------------- -------- 11/14 [google-api-python-client]\n",
      "   ------------------------------- -------- 11/14 [google-api-python-client]\n",
      "   ------------------------------- -------- 11/14 [google-api-python-client]\n",
      "   ------------------------------- -------- 11/14 [google-api-python-client]\n",
      "   ------------------------------- -------- 11/14 [google-api-python-client]\n",
      "   ------------------------------- -------- 11/14 [google-api-python-client]\n",
      "   ------------------------------- -------- 11/14 [google-api-python-client]\n",
      "   ------------------------------- -------- 11/14 [google-api-python-client]\n",
      "   ------------------------------- -------- 11/14 [google-api-python-client]\n",
      "   ------------------------------- -------- 11/14 [google-api-python-client]\n",
      "   ---------------------------------- ----- 12/14 [pydrive]\n",
      "   ------------------------------------- -- 13/14 [llama_index.readers.google]\n",
      "   ------------------------------------- -- 13/14 [llama_index.readers.google]\n",
      "   ------------------------------------- -- 13/14 [llama_index.readers.google]\n",
      "   ---------------------------------------- 14/14 [llama_index.readers.google]\n",
      "\n",
      "Successfully installed future-1.0.0 gkeepapi-0.15.1 google-api-core-2.25.2 google-api-python-client-2.184.0 google-auth-httplib2-0.2.0 google-auth-oauthlib-1.2.2 gpsoauth-2.0.0 httplib2-0.31.0 llama_index.readers.google-0.7.2 oauth2client-4.1.3 proto-plus-1.26.1 pycryptodomex-3.23.0 pydrive-1.3.1 uritemplate-4.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama_index.readers.google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "956640cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.google import GoogleDriveReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a631dcef",
   "metadata": {},
   "source": [
    "https://llamahub.ai/l/readers/llama-index-readers-google?from=readers\n",
    "\n",
    "this is the link to get all google suite readers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "you will need a credentials.json file from Google Cloud to interact with Google Services. To get this file, follow these steps:\n",
    "\n",
    "Create a new project in the Google Cloud Console\n",
    "Go to APIs & Services -> Library and search for the API you want, e.g. Gmail\n",
    "Go to APIs & Services -> Credentials and create a new OAuth client ID\n",
    "Application type: Web application\n",
    "Authorized redirect URIs: http://localhost:8080/ (the last slash seems important)\n",
    "Go to APIs & Services -> OAuth consent screen and make the app external, which allows you to connect your personal Google data once you explicitly add yourself as an allowed test user\n",
    "Download the credentials JSON file from this screen and save it as credentials.json in the root of your projec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91101154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id_='1-ZGC-6UZC_lq_iImaW4nvgFct_jlWpJEZhHwKJHS6Mc.docx', embedding=None, metadata={'file_name': '1-ZGC-6UZC_lq_iImaW4nvgFct_jlWpJEZhHwKJHS6Mc.docx', 'file id': '1-ZGC-6UZC_lq_iImaW4nvgFct_jlWpJEZhHwKJHS6Mc', 'author': 'jerryjliu98', 'file path': 'docs/Agents', 'mime type': 'application/vnd.google-apps.document', 'created at': '2023-12-05T02:23:47.198Z', 'modified at': '2023-12-05T02:24:26.332Z'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='# Agents\\n\\n\\n\\nAn \"agent\" is an automated reasoning and decision engine. It takes in a user input/query and can make internal decisions for executing\\n\\nthat query in order to return the correct result. The key agent components can include, but are not limited to:\\n\\n\\n\\n- Breaking down a complex question into smaller ones\\n\\n- Choosing an external Tool to use + coming up with parameters for calling the Tool\\n\\n- Planning out a set of tasks\\n\\n- Storing previously completed tasks in a memory module\\n\\n\\n\\nResearch developments in LLMs (e.g. [ChatGPT Plugins](https://openai.com/blog/chatgpt-plugins)), LLM research ([ReAct](https://arxiv.org/abs/2210.03629), [Toolformer](https://arxiv.org/abs/2302.04761)) and LLM tooling ([LangChain](https://python.langchain.com/en/latest/modules/agents.html), [Semantic Kernel](https://github.com/microsoft/semantic-kernel)) have popularized the concept of agents.\\n\\n\\n\\n## Agents + LlamaIndex\\n\\n\\n\\nLlamaIndex provides some amazing tools to manage and interact with your data within your LLM application. And it can be a core tool that you use while building an agent-based app.\\n\\n\\n\\n- On one hand, some components within LlamaIndex are \"agent-like\" - these make automated decisions to help a particular use case over your data.\\n\\n- On the other hand, LlamaIndex can be used as a core Tool within another agent framework.\\n\\n\\n\\nIn general, LlamaIndex components offer more explicit, constrained behavior for more specific use cases. Agent frameworks such as ReAct (implemented in LangChain) offer agents that are more unconstrained +\\n\\ncapable of general reasoning.\\n\\n\\n\\nThere are tradeoffs for using both - less-capable LLMs typically do better with more constraints. Take a look at [our blog post on this](https://medium.com/llamaindex-blog/dumber-llm-agents-need-more-constraints-and-better-tools-17a524c59e12) for\\n\\na more information + a detailed analysis.\\n\\n\\n\\n## Learn more\\n\\n\\n\\nOur Putting It All Together section has [more on agents](/understanding/putting_it_all_together/agents.md)', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='1ce7wdv5LO8nWHbx-TnjVn7N-b4w4IUmRmB6NuOZSqj4.docx', embedding=None, metadata={'file_name': '1ce7wdv5LO8nWHbx-TnjVn7N-b4w4IUmRmB6NuOZSqj4.docx', 'file id': '1ce7wdv5LO8nWHbx-TnjVn7N-b4w4IUmRmB6NuOZSqj4', 'author': 'jerryjliu98', 'file path': 'docs/Multimodal', 'mime type': 'application/vnd.google-apps.document', 'created at': '2023-12-05T02:25:02.604Z', 'modified at': '2023-12-05T02:25:09.051Z'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"# Multi-modal\\n\\n\\n\\nLlamaIndex offers capabilities to not only build language-based applications, but also **multi-modal** applications - combining language and images.\\n\\n\\n\\n## Types of Multi-modal Use Cases\\n\\n\\n\\nThis space is actively being explored right now, but there are some fascinating use cases popping up.\\n\\n\\n\\n### Multi-Modal RAG (Retrieval Augmented Generation)\\n\\n\\n\\nAll the core RAG concepts: indexing, retrieval, and synthesis, can be extended into the image setting.\\n\\n\\n\\n- The input could be text or image.\\n\\n- The stored knowledge base can consist of text or images.\\n\\n- The inputs to response generation can be text or image.\\n\\n- The final response can be text or image.\\n\\n\\n\\nCheck out our guides below:\\n\\n\\n\\n```{toctree}\\n\\n---\\n\\nmaxdepth: 1\\n\\n---\\n\\n/examples/multi_modal/gpt4v_multi_modal_retrieval.ipynb\\n\\nMulti-modal retrieval with CLIP </examples/multi_modal/multi_modal_retrieval.ipynb>\\n\\nImage to Image Retrieval </examples/multi_modal/image_to_image_retrieval.ipynb>\\n\\n```\\n\\n\\n\\n### Retrieval-Augmented Image Captioning\\n\\n\\n\\nOftentimes understanding an image requires looking up information from a knowledge base. A flow here is retrieval-augmented image captioning - first caption the image with a multi-modal model, then refine the caption by retrieving from a text corpus.\\n\\n\\n\\nCheck out our guides below:\\n\\n\\n\\n```{toctree}\\n\\n---\\n\\nmaxdepth: 1\\n\\n---\\n\\n/examples/multi_modal/llava_multi_modal_tesla_10q.ipynb\\n\\n```\\n\\n\\n\\n### LLaVa-13, Fuyu-8B and MiniGPT-4 Multi-Modal LLM Models Comparison for Image Reasoning\\n\\n\\n\\nThese notebooks show how to use different Multi-Modal LLM models for image understanding/reasoning. The various model inferences are supported by Replicate or OpenAI GPT4-V API. We compared several popular Multi-Modal LLMs:\\n\\n\\n\\n- GPT4-V (OpenAI API)\\n\\n- LLava-13B (Replicate)\\n\\n- Fuyu-8B (Replicate)\\n\\n- MiniGPT-4 (Replicate)\\n\\n- CogVLM (Replicate)\\n\\n\\n\\nCheck out our guides below:\\n\\n\\n\\n```{toctree}\\n\\n---\\n\\nmaxdepth: 1\\n\\n---\\n\\n/examples/multi_modal/replicate_multi_modal.ipynb\\n\\nGPT4-V: </examples/multi_modal/openai_multi_modal.ipynb>\\n\\n```\\n\\n\\n\\n### Pydantic Program for Generating Structured Output for Multi-Modal LLMs\\n\\n\\n\\nYou can generate `structured` output with new OpenAI GPT4V via LlamaIndex. The user just needs to specify a Pydantic object to define the structure of output.\\n\\n\\n\\nCheck out the guide below:\\n\\n\\n\\n```{toctree}\\n\\n---\\n\\nmaxdepth: 1\\n\\n---\\n\\n/examples/multi_modal/multi_modal_pydantic.ipynb\\n\\n```\\n\\n\\n\\n### Chain of Thought (COT) Prompting for GPT4-V\\n\\n\\n\\nGPT4-V has amazed us with its ability to analyze images and even generate website code from visuals.\\n\\nThis tutorial investigates GPT4-V's proficiency in interpreting bar charts, scatter plots, and tables. We aim to assess whether specific questioning and chain of thought prompting can yield better responses compared to broader inquiries. Our demonstration seeks to determine if GPT-4V can exceed these known limitations with precise questioning and systematic reasoning techniques.\\n\\n\\n\\n```{toctree}\\n\\n---\\n\\nmaxdepth: 1\\n\\n---\\n\\n/examples/multi_modal/gpt4v_experiments_cot.ipynb\\n\\n```\\n\\n\\n\\n### Simple Evaluation of Multi-Modal RAG\\n\\n\\n\\nIn this notebook guide, we'll demonstrate how to evaluate a Multi-Modal RAG system. As in the text-only case, we will consider the evaluation of Retrievers and Generators separately. As we alluded in our blog on the topic of Evaluating Multi-Modal RAGs, our approach here involves the application of adapted versions of the usual techniques for evaluating both Retriever and Generator (used for the text-only case). These adapted versions are part of the llama-index library (i.e., evaluation module), and this notebook will walk you through how you can apply them to your evaluation use-cases.\\n\\n\\n\\n```{toctree}\\n\\n---\\n\\nmaxdepth: 1\\n\\n---\\n\\n/examples/evaluation/multi_modal/multi_modal_rag_evaluation.ipynb\\n\\n```\\n\\n\\n\\n### Using Chroma for Multi-Modal retrieval with single vector store\\n\\n\\n\\nChroma vector DB supports single vector store for indexing both images and texts.\\n\\nCheck out out Chroma + LlamaIndex integration with single Multi-Modal Vector Store for both images/texts index and retrieval.\\n\\n\\n\\n```{toctree}\\n\\n---\\n\\nmaxdepth: 1\\n\\n---\\n\\n/examples/multi_modal/ChromaMultiModalDemo.ipynb\\n\\n```\\n\\n\\n\\n### Multi-Modal RAG on PDF's with Tables using Microsoft `Table Transformer`\\n\\n\\n\\nOne common challenge with RAG (Retrieval-Augmented Generation) involves handling PDFs that contain tables. Parsing tables in various formats can be quite complex.\\n\\n\\n\\nHowever, Microsoft's newly released model, Table Transformer, offers a promising solution for detecting tables within images.\\n\\n\\n\\nIn this notebook, we will demonstrate how to leverage the Table Transformer model in conjunction with GPT4-V to yield better results for images containing tables.\\n\\n\\n\\nThe experiment is divided into the following parts and we compared those 4 options for extracting table information from PDFs:\\n\\n\\n\\n1. Retrieving relevant images (PDF pages) and sending them to GPT4-V to respond to queries.\\n\\n2. Regarding every PDF page as an image, let GPT4-V do the image reasoning for each page. Build Text Vector Store index for the image reasonings. Query the answer against the `Image Reasoning Vector Store`.\\n\\n3. Using Table Transformer to crop the table information from the retrieved images and then sending these cropped images to GPT4-V for query responses.\\n\\n4. Applying OCR on cropped table images and send the data to GPT4/ GPT-3.5 to answer the query.\\n\\n\\n\\n```{toctree}\\n\\n---\\n\\nmaxdepth: 1\\n\\n---\\n\\n/examples/multi_modal/multi_modal_pdf_tables.ipynb\\n\\n```\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='1Dte8R_SjzzQtoq5go8l0I9--U9P5fssdvusSGyiqAw4.docx', embedding=None, metadata={'file_name': '1Dte8R_SjzzQtoq5go8l0I9--U9P5fssdvusSGyiqAw4.docx', 'file id': '1Dte8R_SjzzQtoq5go8l0I9--U9P5fssdvusSGyiqAw4', 'author': 'jerryjliu98', 'file path': 'docs/Chatbots', 'mime type': 'application/vnd.google-apps.document', 'created at': '2023-12-05T02:24:31.413Z', 'modified at': '2023-12-05T02:24:37.149Z'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"# Chatbots\\n\\n\\n\\nChatbots are another extremely popular use case for LLM's. Instead of a single question and answer, a chatbot can handle multiple back-and-forth queries and answers, getting clarification or answering follow-up questions.\\n\\n\\n\\nLlamaIndex gives you the tools to build knowledge-augmented chatbots and agents.\\n\\n\\n\\nHere's some relevant resources:\\n\\n\\n\\n- [Building a chatbot](/understanding/putting_it_all_together/chatbots/building_a_chatbot.md)\\n\\n- [How to build a chatbot](/examples/agent/Chatbot_SEC.ipynb) tutorial\\n\\n- [Using with a LangChain Agent](/community/integrations/using_with_langchain.md)\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='1qSzKrTyj30SUy93zN03st2f8CFBGeScRUZ0ogGb-P3E.docx', embedding=None, metadata={'file_name': '1qSzKrTyj30SUy93zN03st2f8CFBGeScRUZ0ogGb-P3E.docx', 'file id': '1qSzKrTyj30SUy93zN03st2f8CFBGeScRUZ0ogGb-P3E', 'author': 'jerryjliu98', 'file path': 'docs/Extraction', 'mime type': 'application/vnd.google-apps.document', 'created at': '2023-12-05T02:24:47.059Z', 'modified at': '2023-12-05T02:24:56.983Z'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='# Structured Data Extraction\\n\\n\\n\\nLLMs are capable of ingesting large amounts of unstructured data and returning it in structured formats, and LlamaIndex is set up to make this easy.\\n\\n\\n\\nUsing LlamaIndex, you can get an LLM to read natural language and identify semantically important details such as names, dates, address and figures, and return them in a consistent structured format regardless of the source format.\\n\\n\\n\\nThis can be especially useful when you have unstructured source material like chat logs and conversation transcripts.\\n\\n\\n\\nOnce you have structured data you can send them to a database, or you can parse structured outputs in code to automate workflows.\\n\\n\\n\\nExamples:\\n\\n\\n\\n- [Extracting names and locations from descriptions of people](/examples/output_parsing/df_program.ipynb)\\n\\n- [Extracting album data from music reviews](/examples/llm/llama_api.ipynb)', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='1TGiETOFt86El-hI4FbE5lYjo65Cw_l5b6yjKlvl7TVg.docx', embedding=None, metadata={'file_name': '1TGiETOFt86El-hI4FbE5lYjo65Cw_l5b6yjKlvl7TVg.docx', 'file id': '1TGiETOFt86El-hI4FbE5lYjo65Cw_l5b6yjKlvl7TVg', 'author': 'jerryjliu98', 'file path': 'docs/Q&A', 'mime type': 'application/vnd.google-apps.document', 'created at': '2023-12-05T02:25:15.824Z', 'modified at': '2023-12-05T05:48:39.049Z'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='# Q&A\\n\\n\\n\\nOne of the most common use-cases for an LLM application is to answer questions about a set of documents. LlamaIndex has rich support for many forms of question & answering.\\n\\n\\n\\n## Types of question answering use cases\\n\\n\\n\\nQ&A has all sorts of sub-types, such as:\\n\\n\\n\\n### What to do\\n\\n\\n\\n- **Semantic search**: finding data that matches not just your query terms, but your intent and the meaning behind your question. This is sometimes known as \"top k\" search.\\n\\n- **Summarization**: condensing a large amount of data into a short summary relevant to your current question\\n\\n\\n\\n \\n\\n### Where to search\\n\\n\\n\\n- **Over documents**: LlamaIndex can pull in unstructured text, PDFs, Notion and Slack documents and more and index the data within them.\\n\\n- **Over structured data**: if your data already exists in a SQL database, as JSON or as any number of other structured formats, LlamaIndex can query the data in these sources.\\n\\n\\n\\n### How to search\\n\\n\\n\\n- **Combine multiple sources**: is some of your data in Slack, some in PDFs, some in unstructured text? LlamaIndex can combine queries across an arbitrary number of sources and combine them.\\n\\n- **Route across multiple sources**: given multiple data sources, your application can first pick the best source and then \"route\" the question to that source.\\n\\n- **Multi-document queries**: some questions have partial answers in multiple data sources which need to be questioned separately before they can be combined\\n\\n\\n\\n## Examples\\n\\n\\n\\nFor examples of all of these types of Q&A, check out [Q&A](/understanding/putting_it_all_together/q_and_a.md) under \"Putting it all together\".', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from llama_index.readers.google import GoogleDriveReader\n",
    "\n",
    "\n",
    "# Load your credentials.json as a dictionary\n",
    "with open(\"service_account.json\", \"r\") as f:\n",
    "    client_config = json.load(f)\n",
    "\n",
    "# Initialize the reader\n",
    "reader = GoogleDriveReader(service_account_key=client_config)\n",
    "\n",
    "\n",
    "def load_data(folder_id: str):\n",
    "    docs = reader.load_data(folder_id=folder_id)\n",
    "    for doc in docs:\n",
    "        doc.id_ = doc.metadata[\"file_name\"]\n",
    "    return docs\n",
    "\n",
    "\n",
    "docs = load_data(folder_id=\"1RFhr3-KmOZCR5rtp4dlOMNl3LKe1kOA5\")\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baad29eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pipeline.run(documents=docs)\n",
    "print(f\"Ingested {len(nodes)} Nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ca499ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for GoogleDriveReader\nclient_config\n  Input should be a valid dictionary [type=dict_type, input_value='C:\\\\Users\\\\ReDI User\\\\De...93415-15b1f87bef0c.json', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/dict_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m loader = \u001b[43mGoogleDriveReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mUsers\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mReDI User\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDesktop\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mnew\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mfinal-project-193415-15b1f87bef0c.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ReDI User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\llama_index\\readers\\google\\drive\\base.py:124\u001b[39m, in \u001b[36mGoogleDriveReader.__init__\u001b[39m\u001b[34m(self, drive_id, folder_id, file_ids, query_string, is_cloud, credentials_path, token_path, service_account_key_path, client_config, authorized_user_info, service_account_key, file_extractor, raise_errors, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    116\u001b[39m     client_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    117\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m service_account_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    118\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m authorized_user_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    119\u001b[39m ):\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    121\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMust specify `client_config` or `service_account_key` or `authorized_user_info`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    122\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdrive_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrive_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfolder_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfolder_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauthorized_user_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauthorized_user_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mservice_account_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mservice_account_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile_extractor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile_extractor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraise_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraise_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28mself\u001b[39m._creds = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[38;5;28mself\u001b[39m._is_cloud = is_cloud\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ReDI User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pydantic\\main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for GoogleDriveReader\nclient_config\n  Input should be a valid dictionary [type=dict_type, input_value='C:\\\\Users\\\\ReDI User\\\\De...93415-15b1f87bef0c.json', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/dict_type"
     ]
    }
   ],
   "source": [
    "loader = GoogleDriveReader(client_config= r\"C:\\Users\\ReDI User\\Desktop\\new\\final-project-193415-15b1f87bef0c.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb090a01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
